\cite{owen1998scrambling} \cite{heitz:hal02150657}


\subsection{Einleitung}
Quasi-zufällige Sequenzen mit niedriger Abweichung sind deterministisch 
erzeugte Sequenzen, welche die Likelihood-Funktion der Clusterbildung

\begin{equation}\label{eq:Likeli-Hood-Gleichung}
    L_{x}(\delta) = f_{\delta}(x)
\end{equation}

minimieren. Dabei behalten wir die Eigenschaft einer zufälligen Folge, 
den gesamten Platz gleichmäßig auszufüllen. Diese Eigenschaften erinnern
uns an die besprochenen Eigenschaften bei \nameref{ch:Content1:sec:BlueNoise}.
Im Folgenden wird für uns der zweidimensionale Fall wichtig sein, weswegen
wir vom ein- über zum zweidimensionalen schauen werden.

\subsection{Low Discrepency Sequenzen}
Aus dem Vorhandensein einer low discrepency Sequenz folgt dass auch alle 
Subsequenzen derartiger Gestalt sind: Gemessen am Anteil der Punkte innerhalb
einer (Sub-)sequenz.

\begin{equation}\label{eq:Low Discrepency}
    \sup{\abs{\frac{\abs{s_{1}...s_{n} \cap [c,d]}}{N} - \frac{d-c}{b-a}}}
\end{equation}

Jedes x $\in s_{n}$ fällt mit der annähernd gleichen Wahrscheinlichkeit
in das Subintervall [c,d]. Wäre es die selbe Wahrscheinlichkeit hätten 
wir die Uniformität.

\label{sec:quasi monte carlo}
\subsection{Quasi Monte-Carlo Methode}
Diese Methode macht sich die \nameref{eq:Low Discrepency} Folgen zu Nutze
im Gegensatz zu der ursprünglichen Monte-Carlo Methode \ref{ch:Content1:sec:PathTracer},
welche auf pseudozufälligen Zahlen basiert. Im Gegensatz zu ihr haben wir 
hier eine schnellere Konvergenz \textit{O}($\frac{1}{N}$).
Wichtig für das weitere Verständnis ist die Randomisierung einer von Grunde
her deterministische Low Discrepency Sequenz. Ein Verfahren, das 
zufällige Shiften, bildet eine neue Sequenz $y_{i}$ aus $x_{i}$ durch 
eine komponenteweise Addition mit einem zufälligen Wert w.

\label{subsec:onedimensional}
\subsection{1-Dimension}
Diese Arbeit betrachtet Rekurrenz Sequenzen, basierend auf irrationalem 
Bruchrechnen der Form
\begin{equation}\label{eq:Rekurrenz Sequenz}
    R_{1}(\alpha) : t_n = s_0 + n\alpha(mod 1); n = 1,2,3,...
\end{equation}
wobei $\alpha \in \mathbb{I}$ und das (mod 1) einen \textit{"toroidally shift"}
bezeichnet. Will man mit dieser Formel eine Sequenz mit möglichst geringer
Abweichung schaffen, und genau das wollen wir, so wählen wir 
$\alpha = \Phi$ wobei $\Phi \approx 1.618033$ den goldenen Schnitt bezeichnet.
Wie \cite{quasirandomsequencesbyRoberts} gezeigt wird, ist diese Form von 
Sequenz die beste für das \nameref{eq:Rekurrenz Sequenz}.  

\subsection{2-Dimensionen}

Für mehrere Dimensionen, hier zwei, kombiniert man in gängigen Methoden 
einfach zwei \nameref{subsec:onedimensional} eindimensionale Sequenzen.
Für unsere Zwecke untersuchen wir hier die Generalisierung des bereits 
zuvor beschriebenen goldenen Schnitts \nameref{subsec:onedimensional}, wie
hier \cite{krcadinac2006new} beschrieben. 
Die sogenannte Plastische Zahl in ist die Lösung der
Gleichung \nameref{eq:plastische Nummer}
\begin{equation}\label{eq:kubisch}
   x^{3} - x - 1 = 0
\end{equation}
Die Lösung dieser Gleichung lässt sich über die Padovan und Perrin Sequenz
definieren. Damit erhalten wir Plastische Zahl $\Phi$:

\begin{equation} \label{eq:plastische Nummer}
   \Phi = \frac{(9 - \sqrt{69})^{1/3} + (9 + \sqrt{69})^{1/3}}
               {2^{1/3}3^{2/3}} \approx 1.32471795
\end{equation}

\cite{vanderlaanplasticnumber}
\cite{wolframalphaPlastic}
Folgende Gleichung ist auch einfach erweiterbar für höhere Dimensionen.
\begin{equation}\label{eq:1 zu N - Dimensional}
    t_{n} = n\alpha(mod 1), n = 1,2,3,..
    \alpha = (\frac{1}{\Phi_{d}}, \frac{1}{\Phi_{d}^{2}}),
\end{equation}
Dabei ist $\Phi_{d}$ der goldene Schnitt. $\Phi_{d}^{2}$ ist Lösung der
\nameref{eq:kubisch} obigen Gleichung.


\cite{quasirandomsequencesbyRoberts}
\begin{lstlisting}[style=CStyle]
   float g = 1.32471795724474602596; //Plastische Zahl
   float a1 = 1.0/g;
   float a2 = 1.0/(g*g);
   x[n] = (0.5+a1*n) %1; //toroidally shifted
   y[n] = (0.5+a2*n) %1; //toroidally shifted
\end{lstlisting}


\subsection{Dither Texturen und quasi-zufällige Folgen}

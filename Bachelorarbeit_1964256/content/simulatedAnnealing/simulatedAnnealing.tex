Im vorherigen Kapitel, dem Retargeting Schritt \nameref{ch:Content2:sec:Retargeting},
wird eine vorberechnete Retargeting-Textur verwendet. Diese speichert eine
Permutation, die unsere blue noise Textur vom frame t in eine
blue noise Textur vom frame t+1 umwandelt. Diese Permutation wird 
dann auf die Startwerte angewandt bevor das nächste frame t+1 gerendert wird.
Dadurch werden die blue noise Umverteilung der Sorting Phase \nameref{ch:Content2:sec:Sorting}
akkumuliert und die optische Aufwertung erst richtig sichtbar.
Die retarget Textur wird mit Hilfe von \textbf{simulated annealing} 
\cite{hal02158423} berechnet. Wir wollen somit eine approximativ 
optimale Lösung finden: Permutiere Pixel der blue noise Textur von 
frame t bis Sie sehr ähnlich verteilt sind wie die Pixel der blue noise
Textur von frame t+1. Dabei ist die Lokalität der Vertauschungen, 
welche wir bereits in der Sorting Phase\nameref{ch:Content2:sec:Sorting}
verwendet haben, wichtig.

Die Funktion nach der optimiert wird ist an die Formel aus\cite{georgiev2016blue} angelehnt.
\begin{equation}\label{eq:pixel energy function}
    E(M) = \sum_{p \neq q}E(p,q) = 
           \sum_{p \neq q} \mathrm{e}^{-\frac{\Vert{p_{i}-q_{i}}\Vert^{2}}{\sigma_{i}^{2}} -
           \frac{\Vert{p_{s}-q_{s}}\Vert^{d/2}}{\sigma_{s}^{2}}}
\end{equation}
Wähle nach \cite{ulichney1993void} $\sigma_{i} = 2.1$ und $\sigma_{s} = 1$ 
Zu den Pixeln p,q beschreibt $p_{i}$ und $q_{i}$ ihre jeweiligen Koordinaten.
Und $p_{s}$ und $q_{s}$ sind ihre d-dimensionalen Samplewerte.


\begin{algorithm}[H]
    \caption{\textbf{Simulated Annealing} finde sehr gute Lösung}
    \begin{algorithmic}[1]
        \State initialisiere Startzustand $s=s_{0}$
        \For{i=1...maxSteps}
        \State temperature = maxSteps / i;
        \State //Radius für Nachbarschaftssuche ist auf 6 festgesetzt
        \State $s_{neu}\leftarrow$Nachbarzustand(s)
        \State $energy\Delta = energy(s_{neu}) - energy(s)$
        \If{$energy\Delta < 0$}
        \State s = $s_{new}$
        \Else{}
        \If{P(Energie(s), Energie($s_{new}$), temperature)$\ge$ random(0,1)} 
        \State s = $s_{new}$
        \EndIf
        \EndIf
        \EndFor
        \State return Endzustand s;
    \end{algorithmic}
    \label{alg:retargeting}
\end{algorithm}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \centering $e^{-(energy(s_{neu}) - energy(s))/ temperature}$
        \label{fig:APF}
        \caption{Akzeptanzwahrscheinlichkeitsfunktion}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.7\textwidth}
        \centering \includegraphics[interpolate=false,width=\linewidth]{content/simulatedAnnealing/Bilder/exponentialfunktion_as_PDF.png}
        \label{fig:exponentialfunktion}
        \caption{exponentialfunktion}
    \end{subfigure}

    \caption{Die Akzeptanzwahrscheinlichkeitsfunktion P(Energie(s), Energie($s_{new}$), temperature)}
\end{figure}

Die Wahl der Energiefunktion ist angelehnt an die Formulierung der 
Wahrscheinlichkeitsakzeptanzfunktion in \cite{Kirkpatrick671}. 
Diese wird bedeutet für positive Energydeltas, d.h. wenn der der Energiezustand
des Nachbarn höher als der aktuelle ist. Mit absteigender Temperatur erkennt man 
in der Abbildung \ref{fig:exponentialfunktion} eine ebenfalls abnehmende Wahrscheinlichkeit
der Akzeptanz. Dies führt zu dem gewünschten Verhalten, energiehöhere Zustände 
zuzulassen, um somit lokale Maxima zu verlassen. Dies geschieht bei höheren 
Temperaturen häufiger wohingegen bei niederen Temperaturen ein gefundenes Maxima
seltener verlassen wird. Höhere Deltas führen passender Weiße zu einem höheren negativen 
Exponenten und damit eine geringere Akzeptanz als Energiezustände, die nur bisschen 
drüber liegen. Die Wahl des Abkühlvorgangs (also das Updaten der Temperatur über die Zeit)
ist problemspezifisch \cite[S. 9]{Kirkpatrick671}. Dabei muss der Abkühlvorgang derart
gewählt werden, sodass kein bloßer Greedy-Algorithmus entsteht und man in einem lokalen 
Maxima stecken bleibt aber auch kein wahlloses Vertauschen entsteht.

Als Startzustand $s_{0}$ definieren wir eine Permutation, die alle 
Elemente auf sich selbst abbildet.
Um von einem Zustand s zu einem neuem Zustand $s_{new}$ zu kommen,
definieren wir eine Nachbarschaftsfunktion \textit{Nachbarzustand()}. 
Diese kann zwei Elemente genau dann vertauschen, wenn Sie in einem 
gegenseitigen Radius r = 6 erreichbar sind. Dabei vertauschen wir
in jedem Schritt ein Pixelpaar. 
Die Wahrscheinlichkeitsfunktion zur neuen Zustandsannahme
P(Energie(s), Energie($s_{new}$)) beschreibt, ob wir den neu
gewählten Zustand $s_{new}$ übernehmen. Dabei wird klassischerweise die
Akzeptanz von Zuständen mit höherer Energie immer kleiner.(bzw. die 
Toleranz gegenüber größeren Fehlern im Bezug zur Zeit). Die allgemeine Akzeptanz von 
Zuständen mit höherer Energie ist dabei von fundamentaler Bedeutung.
Somit verlassen wir möglicherweiße nur lokale Maxima.
Die zu minimierende Energiefunktion \nameref{eq:pixel energy function} betrachtet
dabei zwei 

\begin{figure}[H]\label{pic:Retargeting}
    \centering
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics[interpolate=false,width=\linewidth]{content/simulatedAnnealing/Bilder/LDR_RGBA_64.png}
        \caption{Blue noise Textur 64x64}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics[interpolate=false,width=\linewidth]{content/simulatedAnnealing/Bilder/retargeted_texture_10312_swaps.png}
        \caption{Permutation; gespeichert in R,G-Channel einer .png}
    \end{minipage}
\end{figure}

\begin{figure}[H]\label{pic:Energy Annealing}
    \centering
    \includegraphics[width=\linewidth]{content/simulatedAnnealing/Bilder/Energy_10313_steps.png}
    \caption{Energieverlauf beim Simulated Annealing}
\end{figure}





